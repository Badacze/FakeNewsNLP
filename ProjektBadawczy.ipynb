{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNcMXXx5wody"
      },
      "source": [
        "ClearML Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaNcekrdhip",
        "outputId": "25389973-11b6-4679-faf2-350dbd05c337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: clearml in ./.venv/lib/python3.13/site-packages (2.0.0)\n",
            "Requirement already satisfied: attrs>=18.0 in ./.venv/lib/python3.13/site-packages (from clearml) (25.3.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in ./.venv/lib/python3.13/site-packages (from clearml) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in ./.venv/lib/python3.13/site-packages (from clearml) (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.10 in ./.venv/lib/python3.13/site-packages (from clearml) (2.3.0)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in ./.venv/lib/python3.13/site-packages (from clearml) (2.3.7.post1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in ./.venv/lib/python3.13/site-packages (from clearml) (7.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in ./.venv/lib/python3.13/site-packages (from clearml) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in ./.venv/lib/python3.13/site-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in ./.venv/lib/python3.13/site-packages (from clearml) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in ./.venv/lib/python3.13/site-packages (from clearml) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in ./.venv/lib/python3.13/site-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in ./.venv/lib/python3.13/site-packages (from clearml) (2.5.0)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in ./.venv/lib/python3.13/site-packages (from clearml) (11.2.1)\n",
            "Requirement already satisfied: referencing<0.40 in ./.venv/lib/python3.13/site-packages (from clearml) (0.36.2)\n",
            "Requirement already satisfied: requests>=2.32.0 in ./.venv/lib/python3.13/site-packages (from clearml) (2.32.4)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in ./.venv/lib/python3.13/site-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.13/site-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.13/site-packages (from jsonschema>=2.6.0->clearml) (0.25.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.0->clearml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.0->clearml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.0->clearml) (2025.6.15)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install clearml\n",
        "\n",
        "from clearml import Task, Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "os.environ[\"CLEARML_API_ACCESS_KEY\"] = \"BF3OQG84RHSYHO86OIYII6Y7VVVMDV\"\n",
        "os.environ[\"CLEARML_API_SECRET_KEY\"] = \"7qQDrf96hXOsbmEio_kUbkEjUqqKaMyq4HB4K1fzOWHjKPelw2HEJdB3RrUvh4FZlA8\"\n",
        "os.environ[\"CLEARML_API_HOST\"] = \"https://api.clear.ml\"\n",
        "os.environ[\"CLEARML_WEB_HOST\"] = \"https://app.clear.ml\"\n",
        "os.environ[\"CLEARML_FILES_HOST\"] = \"https://files.clear.ml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdDwC0Eg3nHV",
        "outputId": "32e0a189-59ab-460f-c37b-465163ed4df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sebastian/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b\n"
          ]
        }
      ],
      "source": [
        "testDataPath = Dataset.get(dataset_id=\"a5958fdaf8cd449bbadc2bf57e5e797b\").get_local_copy()\n",
        "print(testDataPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcbF0rCjD5ZU",
        "outputId": "5decf2d9-00b2-4acc-efe5-6c8182b197c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sebastian/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/train_filtered.tsv\n",
            "/Users/sebastian/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/valid_filtered.tsv\n",
            "/Users/sebastian/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/test_filtered.tsv\n"
          ]
        }
      ],
      "source": [
        "test_val_train_folder=os.listdir(testDataPath)\n",
        "\n",
        "print(testDataPath+\"/\"+test_val_train_folder[0])\n",
        "print(testDataPath+\"/\"+test_val_train_folder[1])\n",
        "print(testDataPath+\"/\"+test_val_train_folder[2])\n",
        "\n",
        "for file in test_val_train_folder:\n",
        "    if \"train\" in file:\n",
        "        train_file = file\n",
        "    elif \"valid\" in file:\n",
        "        valid_file = file\n",
        "    elif \"test\" in file:\n",
        "        test_file = file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wy72t1grm0RJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: (3681, 14)\n",
            "valid: (432, 14)\n",
            "test: (461, 14)\n"
          ]
        }
      ],
      "source": [
        "# wczytujemy do DataFrame\n",
        "columns = [\n",
        "    \"id\", \"label\", \"statement\", \"subjects\", \"speaker\", \"speaker_job\", \"state_info\",\n",
        "    \"party_affiliation\", \"barely_true\", \"false\", \"half_true\",\n",
        "    \"mostly_true\", \"pants_on_fire\", \"context\"\n",
        "]\n",
        "\n",
        "df_train = pd.read_csv(f\"{testDataPath}/{train_file}\", sep='\\t', names=columns, header=None)\n",
        "df_valid = pd.read_csv(f\"{testDataPath}/{valid_file}\", sep='\\t', names=columns, header=None)\n",
        "df_test = pd.read_csv(f\"{testDataPath}/{test_file}\", sep='\\t', names=columns, header=None)\n",
        "\n",
        "print(\"train:\", df_train.shape)\n",
        "print(\"valid:\", df_valid.shape)\n",
        "print(\"test:\", df_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "QF6PBvTMnC-B",
        "outputId": "9ca3d207-ddee-4b91-8218-17c0bf6a88c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subjects</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speaker_job</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>barely_true</th>\n",
              "      <th>false</th>\n",
              "      <th>half_true</th>\n",
              "      <th>mostly_true</th>\n",
              "      <th>pants_on_fire</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>True</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
              "      <td>immigration</td>\n",
              "      <td>rick-perry</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>Radio interview</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  label                                          statement  \\\n",
              "0  11972.json   True  Building a wall on the U.S.-Mexico border will...   \n",
              "\n",
              "      subjects     speaker speaker_job state_info party_affiliation  \\\n",
              "0  immigration  rick-perry    Governor      Texas        republican   \n",
              "\n",
              "   barely_true  false  half_true  mostly_true  pants_on_fire          context  \n",
              "0           30     30         42           23             18  Radio interview  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0pXPR88osZb"
      },
      "source": [
        "# Pre processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lSHNiBso7Zr"
      },
      "source": [
        "### Importy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY0_YpReou7V",
        "outputId": "89bdba65-5543-4b5b-a281-1b980d09916a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import spacy\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7uIQ2qupBEy"
      },
      "source": [
        "### Stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FPoD8RAlpHnW"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uaA3-O44pJae"
      },
      "outputs": [],
      "source": [
        "#2 wersja z użyciem spacy\n",
        "\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#można tez połączyć te dwie metody robiąc listę każdej i potem .concat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVRG8GJeovaO"
      },
      "source": [
        "### Czyszczenie tekstu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XPYfq0ncpOsz"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # remove all digits from text\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # remove html tags\n",
        "    text = re.sub(r'<[^>]*>', '', text)  # additional html tag removal\n",
        "    emojis = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)  # find emojis\n",
        "    text = re.sub(r'[\\W]+', ' ', text) + ' '.join(emojis).replace('-', '')\n",
        "    text = text.strip() # remove\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kkKrgxwpTgR"
      },
      "source": [
        "### Lematyzacja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zXuRJPAWpWiB"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J05mKHztpYnY"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "JqtxAdt9pYG8"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfDsPdYYpeVA"
      },
      "source": [
        "### Tokenizacja + poprzednie funkcje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ATsFHtl11Fhg"
      },
      "outputs": [],
      "source": [
        "def custom_tokenizer(text, cfg):\n",
        "    text = clean_text(text)\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    if cfg[\"lemmatization\"]:\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    if cfg[\"stemming\"]:\n",
        "        tokens = [porter.stem(token) for token in tokens]\n",
        "    if cfg[\"remove_stopwords\"]:\n",
        "        tokens = [t for t in tokens if t not in stop_words]\n",
        "    tokens = [t for t in tokens if len(t) >= cfg[\"min_token_length\"]]\n",
        "\n",
        "    if cfg[\"concat_to_sentence\"]:\n",
        "        return \" \".join(tokens)\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PKhyxq2_Wo"
      },
      "source": [
        "# Metoda Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "N70Lwmsc3Iom"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TGMpGty3Jmf"
      },
      "source": [
        "# Metoda Klasyfikacji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "we2cT86r3SZI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOkJexGjt8LA"
      },
      "source": [
        "# Wywołanie Taska"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "3tesH6x13KeR",
        "outputId": "b2d45e84-ea7e-43df-ef03-2d97afad394e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClearML Task: created new task id=008e4e0c44414f4798f27553ab849c3a\n",
            "ClearML results page: https://app.clear.ml/projects/25cc2e9801f0421ba3bf3ef6bcb791c7/experiments/008e4e0c44414f4798f27553ab849c3a/output/log\n",
            "ClearML results page: https://app.clear.ml/projects/25cc2e9801f0421ba3bf3ef6bcb791c7/experiments/008e4e0c44414f4798f27553ab849c3a/output/log\n",
            "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
            "                                                                                                                                                     statement  \\\n",
            "0                                                                           Says the Annies List political group supports third-trimester abortions on demand.   \n",
            "1                                                                               Health care reform legislation is likely to mandate free sex change surgeries.   \n",
            "2  The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.   \n",
            "\n",
            "                                                                                                          tokens  \n",
            "0                               [say, annies, list, political, group, support, thirdtrimester, abortion, demand]  \n",
            "1                               [health, care, reform, legislation, likely, mandate, free, sex, change, surgery]  \n",
            "2  [chicago, bear, starting, quarterback, last, year, total, number, tenured, faculty, fired, last, two, decade]  \n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-3567307411>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "task_name = \"Wpisać nazwe Taska\"\n",
        "\n",
        "# Tworzenie taska\n",
        "task = Task.init(project_name=\"FakeNewsDetection\", task_name=task_name)\n",
        "\n",
        "# config do preprocesingu\n",
        "cfg_preprocessing ={\n",
        "    \"tokenizer\": True,\n",
        "    \"lemmatization\": True,\n",
        "    \"stemming\": False,\n",
        "    \"remove_stopwords\": True,\n",
        "    \"min_token_length\": 3, # wywala slowa któtsze niz 3\n",
        "    \"concat_to_sentence\": False # czy łaczymy w zdania (True) czy zostawimy jako wyrazy (False)\n",
        "}\n",
        "\n",
        "# preprocessing\n",
        "df_train[\"tokens\"] = df_train[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "df_valid[\"tokens\"] = df_valid[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "df_test[\"tokens\"] = df_test[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "\n",
        "\n",
        "# wyswietl przyklad preprocesingu\n",
        "print(df_train[[\"statement\", \"tokens\"]].head(3))\n",
        "\n",
        "\n",
        "# metoda\n",
        "start_time = time.time()\n",
        "\n",
        "# Tutaj kod ..... = history = model.fit(...)\n",
        "\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "# Tutaj kod ..... = test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "logger = task.get_logger()\n",
        "for epoch in range(len(history.history['loss'])):\n",
        "    logger.report_scalar(\"Loss\", \"train\", value=history.history['loss'][epoch], iteration=epoch)\n",
        "    logger.report_scalar(\"Loss\", \"val\", value=history.history['val_loss'][epoch], iteration=epoch)\n",
        "    logger.report_scalar(\"Accuracy\", \"train\", value=history.history['accuracy'][epoch], iteration=epoch)\n",
        "    logger.report_scalar(\"Accuracy\", \"val\", value=history.history['val_accuracy'][epoch], iteration=epoch)\n",
        "\n",
        "logger.report_scalar(\"Evaluation\", \"Test Loss\", value=test_loss, iteration=0)\n",
        "logger.report_scalar(\"Evaluation\", \"Test Accuracy\", value=test_accuracy, iteration=0)\n",
        "\n",
        "logger.report_scalar(\"Training\", \"Duration (s)\", value=training_duration, iteration=0)\n",
        "\n",
        "# Zamykanie taska\n",
        "task.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
