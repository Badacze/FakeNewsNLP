{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ClearML Template"
      ],
      "metadata": {
        "id": "kNcMXXx5wody"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TwaNcekrdhip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94c461e-12b6-4e4d-f9dc-b1f62eb2ae6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clearml in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.0.2)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.3.7.post1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.4.0)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\n",
            "Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml) (0.36.2)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.3)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.25.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing<0.40->clearml) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install clearml\n",
        "\n",
        "from clearml import Task, Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "os.environ[\"CLEARML_API_ACCESS_KEY\"] = \"BF3OQG84RHSYHO86OIYII6Y7VVVMDV\"\n",
        "os.environ[\"CLEARML_API_SECRET_KEY\"] = \"7qQDrf96hXOsbmEio_kUbkEjUqqKaMyq4HB4K1fzOWHjKPelw2HEJdB3RrUvh4FZlA8\"\n",
        "os.environ[\"CLEARML_API_HOST\"] = \"https://api.clear.ml\"\n",
        "os.environ[\"CLEARML_WEB_HOST\"] = \"https://app.clear.ml\"\n",
        "os.environ[\"CLEARML_FILES_HOST\"] = \"https://files.clear.ml\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testDataPath = Dataset.get(dataset_id=\"a5958fdaf8cd449bbadc2bf57e5e797b\").get_local_copy()\n",
        "print(testDataPath)"
      ],
      "metadata": {
        "id": "HdDwC0Eg3nHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e2ff5e-512a-47d1-c09b-5dda0e07dcb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_val_train_folder=os.listdir(testDataPath)\n",
        "\n",
        "print(testDataPath+\"/\"+test_val_train_folder[0])\n",
        "print(testDataPath+\"/\"+test_val_train_folder[1])\n",
        "print(testDataPath+\"/\"+test_val_train_folder[2])"
      ],
      "metadata": {
        "id": "JcbF0rCjD5ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2da21a-b772-4dfc-c076-f0db70a1dbd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/train_filtered.tsv\n",
            "/root/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/valid_filtered.tsv\n",
            "/root/.clearml/cache/storage_manager/datasets/ds_a5958fdaf8cd449bbadc2bf57e5e797b/test_filtered.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wczytujemy do DataFrame\n",
        "columns = [\n",
        "    \"id\", \"label\", \"statement\", \"subjects\", \"speaker\", \"speaker_job\", \"state_info\",\n",
        "    \"party_affiliation\", \"barely_true\", \"false\", \"half_true\",\n",
        "    \"mostly_true\", \"pants_on_fire\", \"context\"\n",
        "]\n",
        "\n",
        "trainDF = pd.read_csv(testDataPath+\"/\"+test_val_train_folder[0], sep='\\t', names=columns, header=None)\n",
        "valDF = pd.read_csv(testDataPath+\"/\"+test_val_train_folder[1], sep='\\t', names=columns, header=None)\n",
        "testDF = pd.read_csv(testDataPath+\"/\"+test_val_train_folder[2], sep='\\t',names=columns, header=None )\n",
        "\n",
        "df_train = trainDF\n",
        "df_valid = valDF\n",
        "df_test = testDF"
      ],
      "metadata": {
        "id": "wy72t1grm0RJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDF.head(1)"
      ],
      "metadata": {
        "id": "QF6PBvTMnC-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "d89640d4-482b-4149-81ba-d924cfdb33bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  label  \\\n",
              "0  11972.json   True   \n",
              "\n",
              "                                                              statement  \\\n",
              "0  Building a wall on the U.S.-Mexico border will take literally years.   \n",
              "\n",
              "      subjects     speaker speaker_job state_info party_affiliation  \\\n",
              "0  immigration  rick-perry    Governor      Texas        republican   \n",
              "\n",
              "   barely_true  false  half_true  mostly_true  pants_on_fire          context  \n",
              "0           30     30         42           23             18  Radio interview  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99db9c0b-d27d-41f8-8050-beb0148f04e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subjects</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speaker_job</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>barely_true</th>\n",
              "      <th>false</th>\n",
              "      <th>half_true</th>\n",
              "      <th>mostly_true</th>\n",
              "      <th>pants_on_fire</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>True</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will take literally years.</td>\n",
              "      <td>immigration</td>\n",
              "      <td>rick-perry</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>Radio interview</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99db9c0b-d27d-41f8-8050-beb0148f04e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99db9c0b-d27d-41f8-8050-beb0148f04e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99db9c0b-d27d-41f8-8050-beb0148f04e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "testDF",
              "summary": "{\n  \"name\": \"testDF\",\n  \"rows\": 461,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 461,\n        \"samples\": [\n          \"1333.json\",\n          \"8761.json\",\n          \"8667.json\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 461,\n        \"samples\": [\n          \"Obama has \\\"visited more countries and met with more world leaders than any president in his first six months in office.\\\"\",\n          \"A judges order means theres a Constitution exemption zone if you live within 100 miles of the United States border.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 312,\n        \"samples\": [\n          \"cap-and-trade,climate-change,environment\",\n          \"economy,history\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"piers-morgan\",\n          \"herman-cain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 167,\n        \"samples\": [\n          \"U.S. Representative, Florida District 23\",\n          \"Host of \\\"Piers Morgan Tonight\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state_info\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"Washington, D.C.\",\n          \"ohio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"party_affiliation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"newsmaker\",\n          \"talk-show-host\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"barely_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 0,\n        \"max\": 70,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          17,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"false\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 0,\n        \"max\": 114,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          17,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"half_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34,\n        \"min\": 0,\n        \"max\": 160,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          22,\n          160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mostly_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34,\n        \"min\": 0,\n        \"max\": 163,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          2,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pants_on_fire\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 105,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          18,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 333,\n        \"samples\": [\n          \"a news release\",\n          \"a hearing of the congressional \\\"Supercommittee\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre processing\n"
      ],
      "metadata": {
        "id": "p0pXPR88osZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importy"
      ],
      "metadata": {
        "id": "1lSHNiBso7Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import spacy\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "QY0_YpReou7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9496cc9b-409c-4766-f13d-1ca9ea1146b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop words"
      ],
      "metadata": {
        "id": "v7uIQ2qupBEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "FPoD8RAlpHnW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 wersja z użyciem spacy\n",
        "\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#można tez połączyć te dwie metody robiąc listę każdej i potem .concat()"
      ],
      "metadata": {
        "id": "uaA3-O44pJae"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Czyszczenie tekstu"
      ],
      "metadata": {
        "id": "TVRG8GJeovaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # remove all digits from text\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # remove html tags\n",
        "    text = re.sub(r'<[^>]*>', '', text)  # additional html tag removal\n",
        "    emojis = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)  # find emojis\n",
        "    text = re.sub(r'[\\W]+', ' ', text) + ' '.join(emojis).replace('-', '')\n",
        "    text = text.strip() # remove\n",
        "    return text"
      ],
      "metadata": {
        "id": "XPYfq0ncpOsz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lematyzacja"
      ],
      "metadata": {
        "id": "9kkKrgxwpTgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "zXuRJPAWpWiB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming"
      ],
      "metadata": {
        "id": "J05mKHztpYnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "JqtxAdt9pYG8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizacja + poprzednie funkcje"
      ],
      "metadata": {
        "id": "SfDsPdYYpeVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_tokenizer(text, cfg):\n",
        "    text = clean_text(text)\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    if cfg[\"lemmatization\"]:\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    if cfg[\"stemming\"]:\n",
        "        tokens = [porter.stem(token) for token in tokens]\n",
        "    if cfg[\"remove_stopwords\"]:\n",
        "        tokens = [t for t in tokens if t not in stop_words]\n",
        "    tokens = [t for t in tokens if len(t) >= cfg[\"min_token_length\"]]\n",
        "\n",
        "    if cfg[\"concat_to_sentence\"]:\n",
        "        return \" \".join(tokens)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "ATsFHtl11Fhg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metoda Embedding"
      ],
      "metadata": {
        "id": "12PKhyxq2_Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tf_idf(X_train, X_val, X_test):\n",
        "  vectorizer = TfidfVectorizer()  # tutaj można dodać parametry\n",
        "  X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "  X_val_tfidf = vectorizer.transform(X_val)\n",
        "  X_test_tfidf = vectorizer.transform(X_test)\n",
        "  return vectorizer, X_train_tfidf, X_val_tfidf, X_test_tfidf"
      ],
      "metadata": {
        "id": "N70Lwmsc3Iom"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metoda Klasyfikacji"
      ],
      "metadata": {
        "id": "0TGMpGty3Jmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def random_forest(X_train, y_train):\n",
        "  model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "  return model"
      ],
      "metadata": {
        "id": "we2cT86r3SZI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wywołanie Taska"
      ],
      "metadata": {
        "id": "GOkJexGjt8LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_name = \"TF-IDF + Random Forest, full statement\"\n",
        "\n",
        "# Tworzenie taska\n",
        "task = Task.init(project_name=\"FakeNewsDetection\", task_name=task_name)\n",
        "\n",
        "# config do preprocesingu\n",
        "cfg_preprocessing ={\n",
        "    \"tokenizer\": True,\n",
        "    \"lemmatization\": True,\n",
        "    \"stemming\": False,\n",
        "    \"remove_stopwords\": True,\n",
        "    \"min_token_length\": 3, # wywala slowa któtsze niz 3\n",
        "    \"concat_to_sentence\": False # czy łaczymy w zdania (True) czy zostawimy jako wyrazy (False)\n",
        "}\n",
        "\n",
        "# preprocessing\n",
        "df_train[\"tokens\"] = df_train[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "df_valid[\"tokens\"] = df_valid[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "df_test[\"tokens\"] = df_test[\"statement\"].apply(lambda x: custom_tokenizer(x, cfg_preprocessing))\n",
        "\n",
        "\n",
        "# wyswietl przyklad preprocesingu\n",
        "print(df_train[[\"statement\", \"tokens\"]].head(3))\n",
        "\n",
        "\n",
        "# metoda\n",
        "start_time = time.time()\n",
        "\n",
        "y_train = df_train[\"label\"]\n",
        "y_val = df_valid[\"label\"]\n",
        "y_test = df_test[\"label\"]\n",
        "\n",
        "vectorizer, X_train, X_val, X_test = tf_idf(df_train[\"statement\"], df_valid[\"statement\"], df_test[\"statement\"])\n",
        "\n",
        "model = random_forest(X_train, y_train)\n",
        "\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "# Tutaj kod ..... = test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "val_preds = model.predict(X_val)\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "val_acc = accuracy_score(y_val, val_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "logger = task.get_logger()\n",
        "logger.report_scalar(\"Duration\", \"Duration (s)\", value=training_duration, iteration=0)\n",
        "logger.report_scalar(\"Accuracy\", \"Validation Accuracy\", value=val_acc, iteration=0)\n",
        "logger.report_scalar(\"Accuracy\", \"Test Accuracy\", value=test_acc, iteration=0)\n",
        "\n",
        "# Zamykanie taska\n",
        "task.close()"
      ],
      "metadata": {
        "id": "3tesH6x13KeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "de96b611-8433-49bb-c8d9-1a3834ae0a66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=bd2b7822708c4c13b0d049dcaa36467f\n",
            "ClearML results page: https://app.clear.ml/projects/25cc2e9801f0421ba3bf3ef6bcb791c7/experiments/bd2b7822708c4c13b0d049dcaa36467f/output/log\n",
            "                                                                                                                                                     statement  \\\n",
            "0                                                                           Says the Annies List political group supports third-trimester abortions on demand.   \n",
            "1                                                                               Health care reform legislation is likely to mandate free sex change surgeries.   \n",
            "2  The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.   \n",
            "\n",
            "                                                                                                          tokens  \n",
            "0                               [say, annies, list, political, group, support, thirdtrimester, abortion, demand]  \n",
            "1                               [health, care, reform, legislation, likely, mandate, free, sex, change, surgery]  \n",
            "2  [chicago, bear, starting, quarterback, last, year, total, number, tenured, faculty, fired, last, two, decade]  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [432, 461]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-4112266701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \"\"\"\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1518\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [432, 461]"
          ]
        }
      ]
    }
  ]
}